# System Specs

## Guidelines

System specs are an opportunity to test two things really well:

1. &#x20;The UI actually connects to the API calls that are tested in the request specs.
2. &#x20;A series of UI interactions actually produces the correct end state.

The former is obvious, the latter has some important implications.  Here they are:

### System tests avoid data factories

This is not a hard and fast rule.  For example, you wouldn't want to go through the UI to create a new user for every spec. &#x20;

The big win from this is rule is that it protects you from changes in your domain.  When a core model in your app changes, sometimes a lot of tests require updated factories.  The system spec ensures that app still works even if you change domain models.

### System tests run Sidekiq jobs \`inline\`

This rule builds on the previous rule.  The goal of a system test is to test the system with natural data.  This is data that is generated by your application through a series of interactions with the UI.  We want these background jobs to run so that they can produce the appropriate data. &#x20;

Background jobs can be especially tricky to integration test because often there is no indication on the UI to show that they are complete.  By running these jobs `inline` we can ensure that our tests still run in a deterministic manner.  This will prevent some cases from being tested; this will be discussed more.

### System tests use "fake" external services

System tests that rely on external services need to stay simple.  Because these tests are composed of several interactions with the UI, they have to be extremely readable.

This can be difficult when interacting with external systems.  Stubbing via webmock is simply not an option because it is too verbose and does not properly encapsulate the state of the external service.

In these cases, it is best to use a "fake" service.  This is a "fake" service allows you to swap out the API endpoints of the original service, with a service that is running in memory.  Often times this service will have an in memory store so that it will behave in the same manner as the real service.

For example, if you are sending text messages via Twilio, you could stand up a fake Twilio.  The "fake" service will receive all of the API calls to send a text message and record them in the database.  The "fake" service could then be prompted to deliver webhooks for the text messages or even be queried for a list of all sent messages.

### System tests don't use mocks or stubs

This is a big one.  System specs stub or mock ruby classes.  As previously mentioned, external services are often stubbed using a "fake" service.  We want the app to operate as if the user is clicking through the UI.  The possibility of having mocks or stubs in a system test would exclude the tested code from our System test "safety net"

### System tests avoid interacting with the database

System tests should avoid as much as possible interacting with the database.  If you are interacting with the database it could be a sign that your system test is testing too much.  Perhaps the functionality under test is better suited for a request spec.

The goal of this rule is to encourage just working with the UI just as the user would see the app.  System tests are expensive to write and expensive to run.  We want to use system tests for what they are best at, interacting with the UI.  Interacting with the database is a sign that you should consider a Request spec for what you are doing.

### System tests should primarily test the "happy path"

System specs should primarily test the happy path.  System specs are the most expensive tests to write, run, and maintain.  By focusing primarily on the happy path, we are able to do two things:

1. Ensure that all of our UI components connect properly to the APIs that we tested in our Request specs.
2. Provide a safety net against changes to our domain models or database tables.

### Percy Snapshots - keep it simple

Percy snapshots allow us to essentially integration test our CSS.

Using Percy, we are able to compute visual differences between every deploy to production.  If someone changes a CSS attribute and it makes a seemingly unrelated page look bad, we'll know about it.

Percy snapshots are special system tests that call the Percy API to capture a snapshot of the app at specific times. &#x20;

Percy snapshots are very helpful, but the are also very expensive to run.  Do your best to capture the page in 1-2 snapshots.  Avoid using Percy snapshots for every possible state of the page.

## Example

We are building a feature that allows&#x20;
